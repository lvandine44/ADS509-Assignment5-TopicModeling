{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bce2bb89",
   "metadata": {},
   "source": [
    "# ADS 509 Assignment 5.1: Topic Modeling\n",
    "\n",
    "This notebook holds Assignment 5.1 for Module 5 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In this assignment you will work with a categorical corpus that accompanies `nltk`. You will build the three types of topic models described in Chapter 8 of _Blueprints for Text Analytics using Python_: NMF, LSA, and LDA. You will compare these models to the true categories. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d87e2c06",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735fa743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Had to use different syntax for the import code chunk to run without error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58611154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.2\n",
      "  latest version: 24.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.9.1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32393c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 304 0\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/win-64/current_repodata.json HTTP/1.1\" 200 None\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.7.2\n",
      "  latest version: 24.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.9.1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a348b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "import en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e778c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\lvand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a85bce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lvand\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# These libraries may be useful to you\n",
    "\n",
    "# !pip install pyLDAvis==3.4.1 --user  # You need to restart the Kernel after installation.\n",
    "# You also need a Python version => 3.9.0\n",
    "from nltk.corpus import brown\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, TruncatedSVD, LatentDirichletAllocation\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "import en_core_web_sm\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a218df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add any additional libaries you need here\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "494de237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function comes from the BTAP repo.\n",
    "\n",
    "def display_topics(model, features, no_top_words=5):\n",
    "    for topic, words in enumerate(model.components_):\n",
    "        total = words.sum()\n",
    "        largest = words.argsort()[::-1] # invert sort order\n",
    "        print(\"\\nTopic %02d\" % topic)\n",
    "        for i in range(0, no_top_words):\n",
    "            print(\"  %s (%2.2f)\" % (features[largest[i]], abs(words[largest[i]]*100.0/total)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a30a901c",
   "metadata": {},
   "source": [
    "## Getting to Know the Brown Corpus\n",
    "\n",
    "Let's spend a bit of time getting to know what's in the Brown corpus, our NLTK example of an \"overlapping\" corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457c59ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For adventure we have 29 articles.\n",
      "For belles_lettres we have 75 articles.\n",
      "For editorial we have 27 articles.\n",
      "For fiction we have 29 articles.\n",
      "For government we have 30 articles.\n",
      "For hobbies we have 36 articles.\n",
      "For humor we have 9 articles.\n",
      "For learned we have 80 articles.\n",
      "For lore we have 48 articles.\n",
      "For mystery we have 24 articles.\n",
      "For news we have 44 articles.\n",
      "For religion we have 17 articles.\n",
      "For reviews we have 17 articles.\n",
      "For romance we have 29 articles.\n",
      "For science_fiction we have 6 articles.\n"
     ]
    }
   ],
   "source": [
    "# categories of articles in Brown corpus\n",
    "for category in brown.categories() :\n",
    "    print(f\"For {category} we have {len(brown.fileids(categories=category))} articles.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23fb133c",
   "metadata": {},
   "source": [
    "Let's create a dataframe of the articles in of hobbies, editorial, government, news, and romance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18f50b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['editorial','government','news','romance','hobbies'] \n",
    "\n",
    "category_list = []\n",
    "file_ids = []\n",
    "texts = []\n",
    "\n",
    "for category in categories : \n",
    "    for file_id in brown.fileids(categories=category) :\n",
    "        \n",
    "        # build some lists for a dataframe\n",
    "        category_list.append(category)\n",
    "        file_ids.append(file_id)\n",
    "        \n",
    "        text = brown.words(fileids=file_id)\n",
    "        texts.append(\" \".join(text))\n",
    "\n",
    "        \n",
    "        \n",
    "df = pd.DataFrame()\n",
    "df['category'] = category_list\n",
    "df['id'] = file_ids\n",
    "df['text'] = texts \n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "586f47de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add some helpful columns on the df\n",
    "df['char_len'] = df['text'].apply(len)\n",
    "df['word_len'] = df['text'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2128fd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='category'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.groupby('category').agg({'word_len': 'mean'}).plot.bar(figsize=(10,6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "554ffeb5",
   "metadata": {},
   "source": [
    "Now do our TF-IDF and Count vectorizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21a7d247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 4935)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add custom contractions to stop words for consistency across preprocessing\n",
    "custom_stopwords = list(stopwords) + [\"aren\", \"didn\", \"isn\", \"won\", \"ll\", \"ve\", \"re\"]\n",
    "\n",
    "count_text_vectorizer = CountVectorizer(stop_words=custom_stopwords, min_df=5, max_df=0.7)\n",
    "count_text_vectors = count_text_vectorizer.fit_transform(df[\"text\"])\n",
    "count_text_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "875deba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 4935)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_text_vectorizer = TfidfVectorizer(stop_words=custom_stopwords, min_df=5, max_df=0.7)\n",
    "tfidf_text_vectors = tfidf_text_vectorizer.fit_transform(df['text'])\n",
    "tfidf_text_vectors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1062b21",
   "metadata": {},
   "source": [
    "Q: What do the two data frames `count_text_vectors` and `tfidf_text_vectors` hold? \n",
    "\n",
    "A: The two data frames are different representations and breakdowns of the text from the 'text' dataframe. The 'count_text_vectors' data frame holds the term frequency counts of the words in the documents. Each row corresponds to a document, and each column corresponds to a unique term from the 'text' data. The 'tdif_text_vactors' holds the Term Frequency-Inverse Document Frequency values of the words in the documents. TF-IDF measures the importance of a word in a document relative to the corpus. It considers both the frequency of the term in the document and how common or rare the term is across all documents. Both of these data frames do not include the stopwords that have been explicitly stated."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f77c3f94",
   "metadata": {},
   "source": [
    "## Fitting a Non-Negative Matrix Factorization Model\n",
    "\n",
    "In this section the code to fit a five-topic NMF model has already been written. This code comes directly from the [BTAP repo](https://github.com/blueprints-for-text-analytics-python/blueprints-text), which will help you tremendously in the coming sections. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d28745a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_text_model = NMF(n_components=5, random_state=314)\n",
    "W_text_matrix = nmf_text_model.fit_transform(tfidf_text_vectors)\n",
    "H_text_matrix = nmf_text_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a67185e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  mr (0.51)\n",
      "  president (0.45)\n",
      "  kennedy (0.43)\n",
      "  united (0.42)\n",
      "  khrushchev (0.40)\n",
      "\n",
      "Topic 01\n",
      "  said (0.89)\n",
      "  thought (0.42)\n",
      "  man (0.38)\n",
      "  don (0.35)\n",
      "  little (0.34)\n",
      "\n",
      "Topic 02\n",
      "  state (0.40)\n",
      "  development (0.37)\n",
      "  tax (0.33)\n",
      "  sales (0.30)\n",
      "  program (0.25)\n",
      "\n",
      "Topic 03\n",
      "  mrs (2.64)\n",
      "  mr (0.79)\n",
      "  said (0.63)\n",
      "  miss (0.54)\n",
      "  car (0.52)\n",
      "\n",
      "Topic 04\n",
      "  game (1.03)\n",
      "  league (0.75)\n",
      "  ball (0.74)\n",
      "  baseball (0.71)\n",
      "  team (0.67)\n"
     ]
    }
   ],
   "source": [
    "display_topics(nmf_text_model, tfidf_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b46155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_text_matrix shape: (166, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"W_text_matrix shape:\", W_text_matrix.shape)  # Should be (num_documents, num_topics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fee51e9b",
   "metadata": {},
   "source": [
    "Now some work for you to do. Compare the NMF categorization to the original categories from the Brown Corpus.\n",
    "\n",
    "We are interested in the extent to which our NMF categorization agrees or disagrees with the original categories in the corpus. For each topic in your NMF model, tally the Brown categories and interpret the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c8c8eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_category  editorial  hobbies  lore  news  religion  reviews\n",
      "assigned_topic                                                      \n",
      "0                          6        0     0    22         4        0\n",
      "1                          0       29     4     4         4        0\n",
      "2                         14        5    21    17         4        4\n",
      "3                          3        1     0     0         2       12\n",
      "4                          4        1     0     1         3        1\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to hold the tally results of original category vs. NMF model\n",
    "num_documents = W_text_matrix.shape[0]  # Number of documents processed by NMF\n",
    "original_categories = [brown.categories(fileid)[0] for fileid in brown.fileids()][:num_documents]  # Ensure lengths match\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'document_id': range(num_documents),\n",
    "    'assigned_topic': W_text_matrix.argmax(axis=1),  # Get the topic with the highest weight\n",
    "    'original_category': original_categories  # This should match the number of documents processed\n",
    "})\n",
    "\n",
    "# Tally occurrences\n",
    "topic_category_counts = pd.crosstab(results['assigned_topic'], results['original_category'])\n",
    "\n",
    "# Display the counts\n",
    "print(topic_category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1c1ec9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0:\n",
      "  editorial: 6\n",
      "  hobbies: 0\n",
      "  lore: 0\n",
      "  news: 22\n",
      "  religion: 4\n",
      "  reviews: 0\n",
      "\n",
      "Topic 1:\n",
      "  editorial: 0\n",
      "  hobbies: 29\n",
      "  lore: 4\n",
      "  news: 4\n",
      "  religion: 4\n",
      "  reviews: 0\n",
      "\n",
      "Topic 2:\n",
      "  editorial: 14\n",
      "  hobbies: 5\n",
      "  lore: 21\n",
      "  news: 17\n",
      "  religion: 4\n",
      "  reviews: 4\n",
      "\n",
      "Topic 3:\n",
      "  editorial: 3\n",
      "  hobbies: 1\n",
      "  lore: 0\n",
      "  news: 0\n",
      "  religion: 2\n",
      "  reviews: 12\n",
      "\n",
      "Topic 4:\n",
      "  editorial: 4\n",
      "  hobbies: 1\n",
      "  lore: 0\n",
      "  news: 1\n",
      "  religion: 3\n",
      "  reviews: 1\n"
     ]
    }
   ],
   "source": [
    "# Cleaner Interpretation\n",
    "for topic in range(topic_category_counts.shape[0]):\n",
    "    print(f\"\\nTopic {topic}:\")\n",
    "    for category, count in topic_category_counts.loc[topic].items():\n",
    "        print(f\"  {category}: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8d4e2bc",
   "metadata": {},
   "source": [
    "Q: How does your five-topic NMF model compare to the original Brown categories? \n",
    "\n",
    "A: For most topics, the NMF model successful separates distinct topics. However, topic 2 seems to have a more diverse mix of topics potentially suggesting that the corpus is more creative or has more depths in those topics. All other topics appear to have focused content. For example, topic 1 seems to focus on hobbies, topic 00 focuses on news articles, topic 3 focuses on reviews, etc. Lastly, it appears that Topic 4 seems to have low counts of the original text topics, suggesting room for potential growth in preprocessing by adjusting the CountVectorizer or TFDIFVectorizer or further inspecting the custom stop words that were included."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82e37cb5",
   "metadata": {},
   "source": [
    "## Fitting an LSA Model\n",
    "\n",
    "In this section, follow the example from the repository and fit an LSA model (called a \"TruncatedSVD\" in `sklearn`). Again fit a five-topic model and compare it to the actual categories in the Brown corpus. Use the TF-IDF vectors for your fit, as above. \n",
    "\n",
    "To be explicit, we are once again interested in the extent to which this LSA factorization agrees or disagrees with the original categories in the corpus. For each topic in your model, tally the Brown categories and interpret the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07310788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_category  editorial  hobbies  lore  news  religion  reviews\n",
      "assigned_topic                                                      \n",
      "0                         23       28    25    44        15       13\n",
      "1                          0        8     0     0         0        0\n",
      "3                          0        0     0     0         0        3\n",
      "4                          4        0     0     0         2        1\n"
     ]
    }
   ],
   "source": [
    "# Fit the TruncatedSVD LSA Model\n",
    "n_topics = 5\n",
    "lsa_model = TruncatedSVD(n_components=n_topics, random_state=314)\n",
    "lsa_topic_matrix = lsa_model.fit_transform(tfidf_text_vectors)\n",
    "\n",
    "# Create a DataFrame to hold the tally results of original category vs. NMF model\n",
    "num_documents = lsa_topic_matrix.shape[0]  # Number of documents processed by LSA\n",
    "original_categories = [brown.categories(fileid)[0] for fileid in brown.fileids()][:num_documents]  # Ensure lengths match\n",
    "\n",
    "results_lsa = pd.DataFrame({\n",
    "    'document_id': range(num_documents),\n",
    "    'assigned_topic': lsa_topic_matrix.argmax(axis=1),  # Get the topic with the highest weight\n",
    "    'original_category': original_categories  # This should match the number of documents processed\n",
    "})\n",
    "\n",
    "# Tally occurrences\n",
    "topic_category_counts_lsa = pd.crosstab(results_lsa['assigned_topic'], results_lsa['original_category'])\n",
    "\n",
    "# Display and Interpret the Results\n",
    "print(topic_category_counts_lsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a97f9df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0:\n",
      "  editorial: 23\n",
      "  hobbies: 28\n",
      "  lore: 25\n",
      "  news: 44\n",
      "  religion: 15\n",
      "  reviews: 13\n",
      "\n",
      "Topic 1:\n",
      "  editorial: 0\n",
      "  hobbies: 8\n",
      "  lore: 0\n",
      "  news: 0\n",
      "  religion: 0\n",
      "  reviews: 0\n",
      "\n",
      "Topic 3:\n",
      "  editorial: 0\n",
      "  hobbies: 0\n",
      "  lore: 0\n",
      "  news: 0\n",
      "  religion: 0\n",
      "  reviews: 3\n",
      "\n",
      "Topic 4:\n",
      "  editorial: 4\n",
      "  hobbies: 0\n",
      "  lore: 0\n",
      "  news: 0\n",
      "  religion: 2\n",
      "  reviews: 1\n"
     ]
    }
   ],
   "source": [
    "# Cleaner Interpretation of LSA\n",
    "for topic in topic_category_counts_lsa.index:  # Use the index directly to avoid key error\n",
    "    print(f\"\\nTopic {topic}:\")\n",
    "    for category, count in topic_category_counts_lsa.loc[topic].items():\n",
    "        print(f\"  {category}: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4d94d56f",
   "metadata": {},
   "source": [
    "Q: How does your five-topic LSA model compare to the original Brown categories? \n",
    "\n",
    "A: The LSA model does not appear to capture the distinct topics as efficiently as the NMF model did previously. Topic 0 seems to hold most of the diversity while topics 1-4 have very low counts. The low counts suggest that the model is not effectively capturing the thematic elements of the corpus. In simpler terms, it seems that the LSA model is unbalanced. In order to improve the LSA model performance, dimensions could be reduced or stopwords again re-evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "377a886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  said (0.44)\n",
      "  mr (0.25)\n",
      "  mrs (0.22)\n",
      "  state (0.20)\n",
      "  man (0.17)\n",
      "\n",
      "Topic 01\n",
      "  said (4.83)\n",
      "  thought (2.67)\n",
      "  mrs (2.48)\n",
      "  got (2.37)\n",
      "  don (2.32)\n",
      "\n",
      "Topic 02\n",
      "  mrs (3.12)\n",
      "  mr (1.70)\n",
      "  said (1.01)\n",
      "  kennedy (0.80)\n",
      "  khrushchev (0.75)\n",
      "\n",
      "Topic 03\n",
      "  mrs (28.68)\n",
      "  club (6.37)\n",
      "  game (6.05)\n",
      "  jr (5.46)\n",
      "  university (5.07)\n",
      "\n",
      "Topic 04\n",
      "  game (4.99)\n",
      "  league (3.57)\n",
      "  baseball (3.52)\n",
      "  ball (3.44)\n",
      "  team (3.22)\n"
     ]
    }
   ],
   "source": [
    "# call display_topics on your model\n",
    "display_topics(lsa_model, tfidf_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea8b280a",
   "metadata": {},
   "source": [
    "Q: What is your interpretation of the display topics output? \n",
    "\n",
    "A: Weights are fairly strong with each term within each topic. The topics appear to cluster around personal narratives, relationships, and social interactions and a focus on sports in Topic 04. It appears that a lot of the text is recounts of conversations rather than stories of text. Topics 3 and 4 have the strongest weights while aslo seeing the most diversity. This may suggest that the LSA model is more suited to pull the thematic elements regarding topic 3 and 4 from the corpus."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4ab4d29",
   "metadata": {},
   "source": [
    "## Fitting an LDA Model\n",
    "\n",
    "Finally, fit a five-topic LDA model using the count vectors (`count_text_vectors` from above). Display the results using `pyLDAvis.display` and describe what you learn from that visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "802cb8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(n_components=5, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and fit the LDA model\n",
    "lda_model = LatentDirichletAllocation(n_components=5, random_state=42)\n",
    "lda_model.fit(count_text_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aeed6b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the visualization\n",
    "pyLDAvis_data = pyLDAvis.lda_model.prepare(lda_model, count_text_vectors, count_text_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab18adf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 00\n",
      "  said (1.39)\n",
      "  mrs (0.88)\n",
      "  old (0.50)\n",
      "  home (0.47)\n",
      "  man (0.47)\n",
      "\n",
      "Topic 01\n",
      "  use (0.56)\n",
      "  development (0.52)\n",
      "  equipment (0.40)\n",
      "  water (0.37)\n",
      "  000 (0.34)\n",
      "\n",
      "Topic 02\n",
      "  mr (0.59)\n",
      "  state (0.57)\n",
      "  general (0.54)\n",
      "  states (0.53)\n",
      "  tax (0.51)\n",
      "\n",
      "Topic 03\n",
      "  pool (0.56)\n",
      "  small (0.45)\n",
      "  state (0.42)\n",
      "  work (0.37)\n",
      "  great (0.36)\n",
      "\n",
      "Topic 04\n",
      "  state (0.84)\n",
      "  said (0.68)\n",
      "  president (0.63)\n",
      "  united (0.58)\n",
      "  states (0.55)\n"
     ]
    }
   ],
   "source": [
    "# call display_topics on your model\n",
    "display_topics(lda_model, count_text_vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "542a0064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Topic vs Original Category Counts:\n",
      "original_category  editorial  hobbies  lore  news  religion  reviews\n",
      "assigned_topic                                                      \n",
      "0                          4       27     4     3         8        7\n",
      "1                          6        4    10     4         1        0\n",
      "2                          2        0     2    11         1        1\n",
      "3                          0        4     7     4         0        0\n",
      "4                         15        1     2    22         7        9\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have the LDA topic assignments stored\n",
    "lda_topic_matrix = lda_model.transform(count_text_vectors)  # Get topic assignments\n",
    "lda_topic_assignments = lda_topic_matrix.argmax(axis=1)  # Get the topic with the highest weight\n",
    "\n",
    "results_lda = pd.DataFrame({\n",
    "    'document_id': range(num_documents),\n",
    "    'assigned_topic': lda_topic_assignments,\n",
    "    'original_category': original_categories  # Original categories\n",
    "})\n",
    "\n",
    "# Tally occurrences for LDA\n",
    "topic_category_counts_lda = pd.crosstab(results_lda['assigned_topic'], results_lda['original_category'])\n",
    "print(\"LDA Topic vs Original Category Counts:\")\n",
    "print(topic_category_counts_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13a717a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0:\n",
      "  editorial: 4\n",
      "  hobbies: 27\n",
      "  lore: 4\n",
      "  news: 3\n",
      "  religion: 8\n",
      "  reviews: 7\n",
      "\n",
      "Topic 1:\n",
      "  editorial: 6\n",
      "  hobbies: 4\n",
      "  lore: 10\n",
      "  news: 4\n",
      "  religion: 1\n",
      "  reviews: 0\n",
      "\n",
      "Topic 2:\n",
      "  editorial: 2\n",
      "  hobbies: 0\n",
      "  lore: 2\n",
      "  news: 11\n",
      "  religion: 1\n",
      "  reviews: 1\n",
      "\n",
      "Topic 3:\n",
      "  editorial: 0\n",
      "  hobbies: 4\n",
      "  lore: 7\n",
      "  news: 4\n",
      "  religion: 0\n",
      "  reviews: 0\n",
      "\n",
      "Topic 4:\n",
      "  editorial: 15\n",
      "  hobbies: 1\n",
      "  lore: 2\n",
      "  news: 22\n",
      "  religion: 7\n",
      "  reviews: 9\n"
     ]
    }
   ],
   "source": [
    "# Cleaner Interpretation of LSA\n",
    "for topic in topic_category_counts_lda.index:  # Use the index directly to avoid key error\n",
    "    print(f\"\\nTopic {topic}:\")\n",
    "    for category, count in topic_category_counts_lda.loc[topic].items():\n",
    "        print(f\"  {category}: {count}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2c67876",
   "metadata": {},
   "source": [
    "Q: What inference do you draw from the displayed topics for your LDA model? \n",
    "\n",
    "A: In comparison across topics, it is clear that the LDA model is recognizing a notable pattern in political themes. However, on a broader spectrum, none of the weights from the display_topics are significantly strong. It probes the question of if the LDA model is recognizing the necessary patterns and thematic elements of the Brown corpus. \n",
    "\n",
    "Q: Repeat the tallying of Brown categories within your topics. How does your five-topic LDA model compare to the original Brown categories? \n",
    "\n",
    "A: When looking at the counts of the tallying of Brown categories rather than that of weights, it is clear that the LDA model did successfully pull thematic elements and assign to a corresponding topic based on the model logic. However, once again, not every topic has one theme that appears as the strongest, Topic 1 and 3 appear tohave a more general assortment rather than a strong thematic element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6aae75ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_display = pyLDAvis.lda_model.prepare(lda_model, count_text_vectors, count_text_vectorizer, sort_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a89fc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el3279221728612657601873148056\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el3279221728612657601873148056_data = {\"mdsDat\": {\"x\": [0.2037073149969153, -0.13667238591352238, -0.05912062404206699, 0.063943361947577, -0.071857666988903], \"y\": [-0.015831235949750878, 0.1134025759982332, -0.09802691823641861, 0.09544304271468634, -0.09498746452675019], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [27.779111971344022, 17.993564037810742, 13.248041282756484, 8.805049287964966, 32.17423342012379]}, \"tinfo\": {\"Term\": [\"mrs\", \"said\", \"state\", \"tax\", \"states\", \"united\", \"development\", \"government\", \"pool\", \"fiscal\", \"general\", \"equipment\", \"president\", \"mr\", \"small\", \"af\", \"old\", \"car\", \"got\", \"use\", \"went\", \"don\", \"court\", \"design\", \"man\", \"mother\", \"soviet\", \"medical\", \"income\", \"little\", \"ball\", \"mrs\", \"player\", \"baby\", \"anne\", \"hair\", \"clothes\", \"hadn\", \"nice\", \"walked\", \"susan\", \"pale\", \"golf\", \"yards\", \"pink\", \"players\", \"coach\", \"gallery\", \"quietly\", \"orchestra\", \"cup\", \"ham\", \"bedroom\", \"vernon\", \"charlie\", \"dave\", \"waited\", \"listening\", \"golden\", \"yard\", \"woman\", \"bed\", \"wasn\", \"couldn\", \"sat\", \"looked\", \"boy\", \"son\", \"playing\", \"room\", \"got\", \"went\", \"clay\", \"thought\", \"game\", \"knew\", \"eyes\", \"don\", \"club\", \"came\", \"mother\", \"said\", \"miss\", \"night\", \"old\", \"little\", \"know\", \"home\", \"door\", \"away\", \"man\", \"young\", \"good\", \"left\", \"took\", \"way\", \"come\", \"big\", \"right\", \"house\", \"day\", \"going\", \"john\", \"mr\", \"place\", \"af\", \"electronic\", \"precision\", \"components\", \"gear\", \"shelter\", \"objectives\", \"marketing\", \"forests\", \"animals\", \"manufacturer\", \"drill\", \"shipments\", \"interior\", \"interference\", \"measurement\", \"insert\", \"measurements\", \"allocation\", \"designers\", \"phases\", \"structural\", \"site\", \"associations\", \"installation\", \"electronics\", \"fig\", \"textile\", \"screw\", \"tool\", \"design\", \"systems\", \"recreation\", \"missile\", \"materials\", \"machine\", \"engine\", \"equipment\", \"aircraft\", \"sets\", \"heating\", \"products\", \"manufacturers\", \"production\", \"stations\", \"product\", \"development\", \"plant\", \"costs\", \"medical\", \"research\", \"use\", \"standard\", \"range\", \"available\", \"sales\", \"water\", \"1960\", \"areas\", \"cost\", \"number\", \"industry\", \"company\", \"area\", \"system\", \"service\", \"small\", \"work\", \"000\", \"national\", \"program\", \"provide\", \"high\", \"10\", \"motors\", \"bombs\", \"bargaining\", \"virgin\", \"stockholders\", \"churches\", \"ethics\", \"collections\", \"corporate\", \"greece\", \"bus\", \"catholic\", \"gross\", \"vocational\", \"tests\", \"soviets\", \"frontier\", \"deadline\", \"indiana\", \"bridges\", \"alaska\", \"fashioned\", \"commissioners\", \"generations\", \"rico\", \"puerto\", \"trust\", \"beverly\", \"bomb\", \"islands\", \"rayburn\", \"fiscal\", \"foundation\", \"bridge\", \"filing\", \"rehabilitation\", \"income\", \"german\", \"bible\", \"laws\", \"aug\", \"car\", \"driver\", \"anti\", \"berlin\", \"tax\", \"khrushchev\", \"general\", \"soviet\", \"west\", \"return\", \"court\", \"district\", \"europe\", \"1962\", \"union\", \"mr\", \"states\", \"state\", \"nuclear\", \"city\", \"30\", \"law\", \"united\", \"government\", \"day\", \"east\", \"american\", \"great\", \"men\", \"people\", \"said\", \"apparatus\", \"ladder\", \"alexander\", \"discipline\", \"fortunate\", \"shifted\", \"swallowed\", \"painted\", \"ugliness\", \"odd\", \"boat\", \"pool\", \"vehicles\", \"clarity\", \"frames\", \"fortune\", \"dancer\", \"signs\", \"sir\", \"tractor\", \"columns\", \"column\", \"muscles\", \"plastic\", \"paint\", \"collar\", \"discovery\", \"electricity\", \"aboard\", \"contact\", \"push\", \"captain\", \"exercise\", \"cousin\", \"sign\", \"engineer\", \"motor\", \"vacation\", \"insurance\", \"color\", \"learned\", \"eye\", \"muscle\", \"china\", \"cars\", \"letters\", \"small\", \"child\", \"employees\", \"martin\", \"great\", \"work\", \"management\", \"strength\", \"state\", \"find\", \"better\", \"found\", \"large\", \"set\", \"use\", \"life\", \"old\", \"man\", \"american\", \"high\", \"america\", \"people\", \"good\", \"little\", \"men\", \"possible\", \"laos\", \"faculty\", \"republican\", \"cuba\", \"india\", \"democratic\", \"senate\", \"legislature\", \"castro\", \"economic\", \"hughes\", \"democrats\", \"cuban\", \"republicans\", \"gov\", \"assessment\", \"africa\", \"volunteers\", \"congressional\", \"viet\", \"voters\", \"tangible\", \"el\", \"presidential\", \"bond\", \"va\", \"nam\", \"gop\", \"priority\", \"davis\", \"feed\", \"georgia\", \"judge\", \"communist\", \"administration\", \"corps\", \"independence\", \"committee\", \"county\", \"jury\", \"conference\", \"president\", \"kennedy\", \"education\", \"property\", \"secretary\", \"shall\", \"department\", \"vote\", \"government\", \"united\", \"report\", \"state\", \"nations\", \"states\", \"public\", \"policy\", \"peace\", \"members\", \"foreign\", \"schools\", \"000\", \"american\", \"said\", \"program\", \"world\", \"mr\", \"board\", \"college\", \"city\", \"service\", \"york\", \"national\", \"day\", \"people\", \"tax\"], \"Freq\": [306.0, 797.0, 490.0, 176.0, 335.0, 304.0, 202.0, 278.0, 74.0, 108.0, 199.0, 105.0, 298.0, 385.0, 208.0, 74.0, 251.0, 121.0, 146.0, 254.0, 137.0, 176.0, 106.0, 75.0, 280.0, 96.0, 78.0, 102.0, 80.0, 236.0, 62.502437308413896, 302.6148407910006, 47.90011778905542, 35.241133749438774, 34.25710631717359, 35.175331774053845, 32.31994703331712, 31.34810406383353, 27.45073929245738, 46.34908479995815, 26.480316344748594, 26.479027123367036, 26.478673564023417, 26.476742443245012, 25.50653826753315, 24.52862648173226, 22.584902238702167, 21.60769863716453, 21.599157337411867, 20.629621491015133, 19.664444252511302, 19.6635722251855, 20.59687085682403, 19.65062349314028, 18.691644618218994, 18.691109614508278, 18.69079587627383, 18.689986867374174, 20.550977535760264, 18.683929182162114, 53.23607767293953, 34.466252699419634, 55.61215119025234, 50.74134087704698, 36.19522649259131, 80.24197242521103, 77.08554929568153, 69.14267707440086, 37.702517962511536, 94.40385882352857, 131.42686000754955, 122.8104745445553, 74.789618470614, 121.65250610808357, 79.57183499282345, 79.25691377644493, 85.13436449514903, 143.9406976808248, 95.00529709656473, 132.83972655205042, 82.54742481455455, 478.12609843585807, 81.18647656471944, 115.73360400259207, 170.7027602603174, 160.28225975797983, 133.5797525079498, 163.14606216118995, 58.29561646117303, 89.39436188336025, 162.72478882710163, 95.072341115164, 161.67957059026986, 105.11274387785312, 86.0189442740309, 140.55938707125497, 107.88366357272716, 88.37227991195579, 108.39838666895388, 111.93798167763711, 122.95092854184868, 89.90084439570421, 96.89749858407862, 100.29524826655778, 88.02747812219647, 73.89561436824485, 26.05163023649096, 22.261869937879958, 21.299733032625777, 21.2970201316343, 57.17136939557893, 18.421647387545924, 40.495163819078556, 15.53596973042743, 16.429508879628706, 18.226174372271217, 31.850831814018264, 13.603677481839542, 38.956862149859234, 34.302090460153906, 11.705767380521069, 11.702498123620753, 12.600061885651243, 11.642834241613503, 10.73662228486207, 13.413385639064533, 8.824909221789959, 48.18438941522554, 8.761559934326884, 7.8645963369842615, 29.657617405683997, 28.74954637124583, 25.93072440913022, 15.528445173433814, 27.693849020173463, 68.3191427849392, 34.438764098066294, 32.79157828115425, 35.98484070986299, 45.49805134320458, 46.35515758507331, 26.799196642709397, 89.16533722227453, 48.5022539452718, 32.73165453204349, 19.87691894213067, 49.728352742219975, 34.378552555927904, 61.594515235785295, 45.3257172898667, 38.66478881896634, 116.35303829155971, 56.45037195724989, 56.13705047132167, 66.24477409285569, 66.88554153477403, 125.19899999077654, 41.87726926529834, 49.87960041421673, 68.54746566277467, 67.49357336307891, 82.0083810412829, 71.37767083189202, 59.530921207250934, 64.92404084705814, 68.10295374270959, 56.292272315695854, 66.21125348179764, 67.51485145770617, 65.90781268494551, 72.21919327996146, 70.50699457109114, 74.03275229663923, 75.03384503971454, 69.1614308293664, 67.32793458299419, 56.194575823904934, 62.44696682864216, 58.11979649594542, 43.74186418652908, 17.793271021800198, 12.231807473214296, 13.934823340743371, 18.585580553740797, 20.16374724671505, 7.568518096234462, 6.6260032716099255, 6.622764738966994, 5.735122140323559, 17.05173151017962, 26.774959362581594, 18.642771750050034, 12.155929773309651, 23.3475257522222, 5.617867164651591, 4.81023546869899, 4.808150774783244, 4.797175261314525, 15.994119221022133, 16.697602495288894, 4.741378723630323, 11.036787509499304, 9.367375691676882, 16.26985371432547, 16.269853702177386, 30.864509933769888, 9.26426050615433, 15.93903080638917, 12.967229535341202, 36.03117601608883, 83.39445507880646, 25.717958316997056, 38.11909954907813, 14.270711394077813, 14.682140373698328, 53.66583360463574, 22.581013497678455, 18.355946972711664, 32.536634657610534, 17.162784066630117, 69.89080643625226, 20.585097206813632, 36.752823003148634, 39.09995951151239, 84.59168477186368, 41.97101518669614, 88.83934415328163, 44.0963670994146, 54.10724153963567, 38.24057106830425, 53.211892328916925, 36.065472180946784, 24.2375268418454, 23.180052560980396, 34.78529883554245, 96.55872225765168, 86.6376408422414, 94.02529989291256, 35.2778863629707, 55.22852321282814, 40.67598021189929, 37.85563067236755, 58.55948774538582, 52.98685344939598, 52.728795861636534, 35.93982648293579, 46.30863957971315, 41.12615321168027, 39.35482421651148, 40.87710672610583, 42.786471034618856, 9.316317006363333, 8.34901177922384, 21.64152290612889, 5.662600033260014, 4.748550056045425, 4.745828694645092, 4.635730332117424, 13.867000938789294, 4.608814203888724, 6.868702483997787, 33.726721841369155, 61.71083903384989, 34.14612155524399, 7.487377231815216, 16.477549697402083, 8.123645769275322, 7.354365431602763, 27.245009550573972, 20.434529738668246, 17.1200757247488, 4.711969076057305, 12.104116588895604, 8.742887485313801, 18.037379838011304, 10.006730490665971, 5.985331116842585, 6.54845962018772, 8.541901581392317, 7.229440617123353, 16.94116902077261, 19.94679222825474, 15.579425414704716, 17.419287605124186, 16.232937295121324, 30.581498304925244, 19.231588456847618, 21.860137014493418, 20.752473320638877, 19.012683110442218, 28.906869976875093, 16.941968131076063, 19.239651416954416, 11.566359889162568, 17.538209977095264, 26.272637172108354, 20.54662576564013, 49.28536014827233, 24.895331493281432, 21.407805881130127, 18.93505776572927, 39.078896877939464, 40.09012174655264, 24.76405580198966, 22.127059056336254, 45.6914603774916, 27.381716499315548, 29.500718525603244, 27.437625385226713, 27.826858099814466, 28.819208438519315, 30.486587957544714, 27.23792749269662, 29.37821741986873, 29.05924366907914, 28.114684609730322, 27.121491785897412, 23.03890055266183, 25.118426670653893, 25.223327673440604, 23.562287321504453, 23.295160382858075, 22.184825059472672, 50.27665940973211, 53.069759978433524, 39.47698136154882, 37.51175537276289, 37.505847984864346, 60.420935661017474, 50.82278446762274, 31.616384305323415, 29.648538992074354, 82.22318172888137, 24.74507649124619, 23.76228485161272, 20.814133411922842, 19.836068035230735, 19.831400472039917, 17.87214451721398, 17.85646846707971, 18.775776914282645, 15.904771480845936, 14.926218755824907, 14.923601831205639, 14.920277067965285, 14.884410457094718, 14.884841843632675, 13.940935914149298, 13.922247460802897, 12.962389487991045, 12.960533247834693, 12.959036427040553, 12.958430804881221, 92.44555759415844, 40.56878888258097, 47.57761606169253, 68.91096419391306, 122.70031281433897, 70.97607543376809, 27.377571233426995, 99.70887777062983, 94.501121950475, 44.89319953461089, 48.09748263927415, 250.63022889106645, 114.12628215159607, 77.65731384352037, 84.87689903346077, 105.36447310555441, 109.85497344335116, 131.21377126031905, 50.38657173722688, 212.8643338752417, 230.00326364713825, 76.7576223139806, 337.08386617748585, 67.19729417184483, 220.36458004196618, 144.87754072798856, 77.60088376985723, 87.05249825458448, 101.49084059779814, 79.08596192115301, 73.36817199372338, 163.8798347790053, 148.51618823034042, 273.08497241549594, 125.73033422847767, 130.5621244516781, 163.78125932922808, 105.21488964683833, 86.86912483677926, 108.77259173006993, 101.73489900186341, 87.3600490005781, 93.40511688380151, 99.14839988130153, 95.0632109045883, 87.65231143890374], \"Total\": [306.0, 797.0, 490.0, 176.0, 335.0, 304.0, 202.0, 278.0, 74.0, 108.0, 199.0, 105.0, 298.0, 385.0, 208.0, 74.0, 251.0, 121.0, 146.0, 254.0, 137.0, 176.0, 106.0, 75.0, 280.0, 96.0, 78.0, 102.0, 80.0, 236.0, 63.26080599792028, 306.6737347544497, 48.65701368744127, 36.00028104683214, 35.02629733568739, 35.99613992957504, 33.079495691546406, 32.10592093184662, 28.211475222824376, 47.647853712234046, 27.238057739964763, 27.23793173139022, 27.2380560032168, 27.237990553421874, 26.264407945510374, 25.290772734654798, 23.343681812615753, 22.36993835570038, 22.369989134673062, 21.39615215512514, 20.422866200621794, 20.42285516052449, 21.39405389329069, 20.42217271808061, 19.449346284999468, 19.449286514497352, 19.449285592979876, 19.449234084192348, 21.391149822257134, 19.449036619146685, 55.48481712155158, 35.95257854781441, 58.406963758817554, 53.51924047143797, 37.933184292645144, 85.66979150589937, 82.53060356080316, 73.8067995089862, 39.8739556432534, 103.06454648476524, 146.97423006481998, 137.04729243778442, 82.66561670193104, 139.64999289632092, 90.31668089217922, 90.50373424580847, 98.04055665765628, 176.92020589006216, 111.63694017836923, 162.18114973792157, 96.4715806167346, 797.358201277997, 99.28204014504023, 151.49982153762193, 251.06656068351606, 236.696517523215, 190.4948594893754, 266.3409372915932, 69.71218069856934, 122.74989262718542, 280.05174210705405, 134.9980637785379, 306.3883453940537, 160.8573736092013, 120.36586912820995, 273.56887035250037, 184.15425283410207, 127.10183150659026, 212.5085012925033, 232.9988871555191, 301.6975285727634, 133.07451421805405, 168.48693018445624, 385.6103179387894, 189.30315236393727, 74.83457684391601, 26.862469688517134, 23.022878621130758, 22.063213367114688, 22.0631857699671, 59.525144604935754, 19.18434172967253, 42.18302988031573, 16.305007133276856, 17.26678428810281, 19.17786825073811, 33.54643900932787, 14.386565337681972, 41.291894054656005, 36.410376173914486, 12.466803747963684, 12.46689069375547, 13.42329351177015, 12.464174562468004, 11.50697343248299, 14.385285699901221, 9.587809925707417, 52.7165961154133, 9.587668767593563, 8.62826218734224, 32.65122229084981, 31.69081241644154, 28.734142417912967, 17.231973534154466, 30.732409800602635, 75.84960465630806, 38.39345896814125, 36.52503184752833, 40.17539628437134, 51.608584924229355, 52.7892088594585, 29.77177117830156, 105.90611068017458, 56.78175909328212, 37.399128679432756, 22.083893127053898, 63.288379023595745, 42.060197977739506, 85.22446046350753, 59.45125081150628, 48.88560695938368, 202.2249614771133, 80.30482603038648, 81.59219251834901, 102.38710608600852, 103.9253422003452, 254.52943404751636, 55.62073546748663, 72.90578762935579, 120.30327808475157, 119.07270771703729, 162.70352595518622, 130.39713038041475, 99.90338268007463, 117.0643424131803, 137.23233437314113, 97.67835752046628, 138.93435003300263, 146.10509449332562, 144.32939705537663, 207.02528326141015, 208.18771983243087, 257.88327816868565, 283.2806771370106, 215.61076664674343, 232.69347937728614, 114.95206418596311, 217.3618104357245, 146.56620890340173, 44.51626965762455, 18.56270438803323, 13.001237558264902, 14.863908031513185, 20.479624629899764, 22.252239530597326, 8.368085406777228, 7.441641121807437, 7.442404825056303, 6.513030736470801, 19.46608967214841, 30.772867367418325, 21.44380496325642, 13.987803348798876, 27.04297893777637, 6.52023675764502, 5.585762871826747, 5.5863094779024625, 5.586498629324425, 18.652252869767697, 19.56108102090047, 5.590147461173059, 13.04800992224057, 11.207172408766855, 19.63526055846694, 19.635260559296558, 37.353076097017286, 11.213580121353537, 19.52215176449068, 15.902970107394546, 44.97534198468962, 108.60387207933273, 32.69612088740791, 50.37227713314286, 17.790016257685703, 18.7233892077697, 80.80120792341638, 30.666409931952145, 24.337029081753446, 47.807212338829004, 22.528353882471794, 121.77721001255159, 28.02422870490534, 57.68988981085903, 63.451310471075914, 176.54103640742542, 71.13735727032503, 199.06910784637319, 78.85773399898, 104.40953066188413, 65.09164033156908, 106.71231298411197, 66.55369199238955, 36.361526191524476, 33.876809907030335, 67.58127388611668, 385.6103179387894, 335.40791221118417, 490.5923383036065, 76.84474620831934, 213.89286320800278, 114.57669953866336, 98.81042501818555, 304.3077778285574, 278.3402310331512, 301.6975285727634, 93.85499721004474, 261.7757419545065, 198.90489307004245, 191.25359754568547, 263.5247864655676, 797.358201277997, 10.08700386500394, 9.176971384735792, 23.89374922649001, 6.432704595173442, 5.519141071611949, 5.5192773704609825, 5.525129641245997, 16.619565754493788, 5.528323266949681, 8.270060897807305, 40.61412044863076, 74.80716080024162, 41.565597603997574, 9.186979543673253, 20.326022037232686, 10.176194597983855, 9.242324225529206, 35.255492007885984, 26.72900149262257, 23.250581520865218, 6.44712938282756, 16.63761870732936, 12.031403014096075, 25.091472076738842, 13.935825179127427, 8.358651829365925, 9.243392112450008, 12.069267266672059, 10.233245788828706, 24.074217200528043, 28.79926188664361, 23.30639385270426, 26.937440650941333, 26.183596323052175, 56.135120499970505, 32.64440190345951, 39.26805483171392, 37.25476149282511, 33.51805954206546, 62.2957400917815, 30.039726025151523, 36.434494701489, 17.726996323710942, 32.86138123390289, 65.11818439083929, 44.3629488235254, 208.18771983243087, 65.35294796872013, 51.44191829003585, 41.08468713926328, 198.90489307004245, 257.88327816868565, 83.96619567708207, 61.73045557994969, 490.5923383036065, 114.72697002848415, 157.7799724277839, 124.7792502897347, 142.8728950133192, 167.38860245460307, 254.52943404751636, 159.81123690607598, 251.06656068351606, 280.05174210705405, 261.7757419545065, 217.3618104357245, 89.15533259988305, 263.5247864655676, 306.3883453940537, 236.696517523215, 191.25359754568547, 124.9686985096915, 51.03573223438191, 53.97134609961399, 40.23330819613518, 38.26913293495966, 38.26904088444891, 61.80135965638263, 52.00789390300813, 32.376575718302924, 30.412338627146333, 84.39118344712946, 25.502461428958252, 24.52030859240888, 21.57415810169348, 20.59220115458909, 20.59207581043631, 18.628100241916467, 18.627129826446115, 19.608262365510054, 16.66388941388723, 15.681941401111098, 15.68181811150427, 15.681783372741933, 15.679103450929475, 15.67964064845524, 14.69974343915855, 14.698619244469574, 13.71785027317662, 13.7178066902504, 13.717755659685277, 13.717785369337385, 98.96638528994472, 43.07546169893863, 50.88439269578441, 74.32884701790726, 134.88954052953693, 77.36645273631976, 29.357860296954836, 111.45733479851859, 105.54877371111006, 49.00476888355458, 52.83023241172537, 298.4105736164419, 131.52278252850994, 87.90530574384009, 97.60378610630119, 123.91594151610936, 129.82151173096148, 160.08932732444927, 56.60340207829105, 278.3402310331512, 304.3077778285574, 90.65685561863577, 490.5923383036065, 79.77503290925542, 335.40791221118417, 202.61535601191522, 95.52829386744783, 110.98961927613388, 141.97529008826797, 102.06733953696275, 92.47938503216733, 283.2806771370106, 261.7757419545065, 797.358201277997, 232.69347937728614, 255.0557855012412, 385.6103179387894, 176.17422872187905, 126.03831468459998, 213.89286320800278, 207.02528326141015, 147.77972832759332, 215.61076664674343, 301.6975285727634, 263.5247864655676, 176.54103640742542], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.313, -4.7357, -6.579, -6.886, -6.9143, -6.8878, -6.9725, -7.003, -7.1358, -6.612, -7.1718, -7.1718, -7.1718, -7.1719, -7.2092, -7.2483, -7.3309, -7.3751, -7.3755, -7.4214, -7.4694, -7.4694, -7.423, -7.4701, -7.5201, -7.5201, -7.5201, -7.5202, -7.4253, -7.5205, -6.4734, -6.9082, -6.4298, -6.5214, -6.8592, -6.0631, -6.1033, -6.212, -6.8184, -5.9006, -5.5697, -5.6375, -6.1335, -5.647, -6.0715, -6.0755, -6.0039, -5.4788, -5.8942, -5.559, -6.0348, -4.2783, -6.0514, -5.6969, -5.3082, -5.3712, -5.5535, -5.3535, -6.3826, -5.9551, -5.3561, -5.8935, -5.3626, -5.7931, -5.9936, -5.5025, -5.7671, -5.9666, -5.7624, -5.7302, -5.6364, -5.9495, -5.8745, -5.84, -5.9705, -5.7112, -6.7538, -6.911, -6.9552, -6.9553, -5.9678, -7.1004, -6.3127, -7.2707, -7.2148, -7.111, -6.5528, -7.4036, -6.3514, -6.4787, -7.5538, -7.5541, -7.4802, -7.5592, -7.6402, -7.4176, -7.8363, -6.1389, -7.8435, -7.9515, -6.6242, -6.6553, -6.7585, -7.2712, -6.6927, -5.7897, -6.4747, -6.5237, -6.4308, -6.1962, -6.1776, -6.7255, -5.5234, -6.1323, -6.5256, -7.0243, -6.1073, -6.4765, -5.8933, -6.2, -6.359, -5.2573, -5.9805, -5.9861, -5.8205, -5.8109, -5.184, -6.2792, -6.1043, -5.7864, -5.8019, -5.6071, -5.7459, -5.9274, -5.8407, -5.7929, -5.9833, -5.821, -5.8015, -5.8256, -5.7342, -5.7582, -5.7094, -5.696, -5.7775, -5.8043, -5.9851, -5.8796, -5.9514, -5.9294, -6.8289, -7.2037, -7.0733, -6.7853, -6.7038, -7.6837, -7.8167, -7.8172, -7.9611, -6.8715, -6.4203, -6.7823, -7.2099, -6.5572, -7.9818, -8.137, -8.1374, -8.1397, -6.9355, -6.8925, -8.1514, -7.3065, -7.4705, -6.9184, -6.9184, -6.2781, -7.4816, -6.939, -7.1453, -6.1233, -5.2842, -6.4605, -6.067, -7.0495, -7.0211, -5.725, -6.5906, -6.7978, -6.2254, -6.865, -5.4608, -6.6832, -6.1035, -6.0416, -5.2699, -5.9708, -5.2209, -5.9214, -5.7168, -6.0638, -5.7335, -6.1224, -6.5198, -6.5644, -6.1585, -5.1376, -5.246, -5.1642, -6.1445, -5.6963, -6.0021, -6.074, -5.6377, -5.7377, -5.7426, -6.1259, -5.8724, -5.9911, -6.0351, -5.9972, -5.9515, -7.0674, -7.1771, -6.2246, -7.5653, -7.7414, -7.7419, -7.7654, -6.6697, -7.7712, -7.3722, -5.7809, -5.1767, -5.7686, -7.286, -6.4972, -7.2044, -7.3039, -5.9943, -6.282, -6.459, -7.7491, -6.8057, -7.131, -6.4068, -6.9959, -7.5099, -7.42, -7.1542, -7.321, -6.4695, -6.3061, -6.5533, -6.4416, -6.5122, -5.8788, -6.3427, -6.2145, -6.2665, -6.3541, -5.9351, -6.4694, -6.3422, -6.8511, -6.4348, -6.0307, -6.2765, -5.4016, -6.0845, -6.2355, -6.3582, -5.6336, -5.6081, -6.0898, -6.2024, -5.4773, -5.9893, -5.9148, -5.9873, -5.9732, -5.9382, -5.8819, -5.9946, -5.919, -5.9299, -5.9629, -5.9989, -6.162, -6.0756, -6.0714, -6.1396, -6.151, -6.1998, -6.6775, -6.6234, -6.9193, -6.9704, -6.9706, -6.4937, -6.6667, -7.1414, -7.2056, -6.1856, -7.3864, -7.4269, -7.5594, -7.6075, -7.6078, -7.7118, -7.7127, -7.6625, -7.8284, -7.8919, -7.8921, -7.8923, -7.8947, -7.8947, -7.9602, -7.9616, -8.033, -8.0331, -8.0333, -8.0333, -6.0684, -6.892, -6.7327, -6.3622, -5.7853, -6.3327, -7.2853, -5.9928, -6.0464, -6.7908, -6.7218, -5.0711, -5.8577, -6.2427, -6.1538, -5.9376, -5.8959, -5.7182, -6.6753, -5.2344, -5.157, -6.2544, -4.7747, -6.3874, -5.1998, -5.6192, -6.2435, -6.1285, -5.9751, -6.2245, -6.2996, -5.4959, -5.5944, -4.9853, -5.7609, -5.7232, -5.4965, -5.939, -6.1306, -5.9058, -5.9727, -6.125, -6.0581, -5.9984, -6.0405, -6.1217], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.2688, 1.2676, 1.2652, 1.2596, 1.2587, 1.2578, 1.2577, 1.257, 1.2536, 1.2532, 1.2527, 1.2526, 1.2526, 1.2525, 1.2516, 1.2503, 1.2478, 1.2462, 1.2458, 1.2444, 1.243, 1.243, 1.2429, 1.2424, 1.2411, 1.2411, 1.2411, 1.2411, 1.2408, 1.2408, 1.2395, 1.2387, 1.2319, 1.2276, 1.234, 1.2154, 1.2126, 1.2156, 1.2249, 1.1931, 1.1691, 1.1712, 1.1808, 1.1429, 1.1542, 1.1482, 1.1397, 1.0746, 1.1196, 1.0813, 1.125, 0.7695, 1.0797, 1.0116, 0.8951, 0.891, 0.926, 0.7908, 1.102, 0.9638, 0.738, 0.9303, 0.6416, 0.8554, 0.9449, 0.615, 0.7462, 0.9175, 0.6077, 0.5478, 0.3832, 0.8887, 0.7277, -0.0658, 0.5152, 1.7025, 1.6845, 1.6815, 1.6799, 1.6798, 1.6748, 1.6746, 1.6743, 1.6668, 1.6655, 1.6643, 1.6633, 1.6592, 1.6569, 1.6555, 1.6522, 1.6519, 1.6519, 1.647, 1.6459, 1.6452, 1.6322, 1.6253, 1.6251, 1.6225, 1.619, 1.6178, 1.6125, 1.6111, 1.611, 1.6106, 1.6065, 1.6073, 1.605, 1.5891, 1.5852, 1.61, 1.5431, 1.5576, 1.5819, 1.6099, 1.474, 1.5135, 1.3904, 1.4439, 1.4806, 1.1624, 1.3627, 1.3412, 1.2798, 1.2745, 1.0056, 1.4313, 1.3356, 1.1527, 1.1475, 1.03, 1.1126, 1.1974, 1.1257, 1.0145, 1.164, 0.974, 0.9432, 0.9313, 0.662, 0.6324, 0.4672, 0.3867, 0.5781, 0.475, 0.9995, 0.4679, 0.7902, 2.0038, 1.979, 1.9603, 1.9568, 1.9243, 1.9228, 1.9209, 1.9052, 1.9046, 1.8941, 1.8889, 1.8822, 1.8813, 1.881, 1.8744, 1.8724, 1.8718, 1.8713, 1.869, 1.8676, 1.863, 1.8566, 1.8539, 1.842, 1.8333, 1.8333, 1.8305, 1.8304, 1.8185, 1.8172, 1.7996, 1.7572, 1.7813, 1.7426, 1.8009, 1.7782, 1.6121, 1.7153, 1.7393, 1.6365, 1.7493, 1.4661, 1.7128, 1.5705, 1.5372, 1.2856, 1.4937, 1.2145, 1.4401, 1.364, 1.4894, 1.3255, 1.4086, 1.6157, 1.6419, 1.3572, 0.6366, 0.6677, 0.3693, 1.2428, 0.6673, 0.9857, 1.0619, 0.3733, 0.3625, 0.2771, 1.0614, 0.2892, 0.4451, 0.4403, 0.1577, -0.9038, 2.3504, 2.3353, 2.3308, 2.3023, 2.2795, 2.2789, 2.2543, 2.2488, 2.2479, 2.2442, 2.244, 2.2374, 2.2332, 2.2253, 2.2199, 2.2046, 2.2013, 2.1721, 2.1613, 2.1238, 2.1163, 2.1117, 2.1106, 2.0998, 2.0986, 2.0959, 2.0852, 2.0842, 2.0824, 2.0785, 2.0626, 2.0271, 1.9939, 1.9518, 1.8225, 1.9007, 1.8441, 1.8447, 1.8629, 1.662, 1.8571, 1.7913, 2.0029, 1.8019, 1.5222, 1.6601, 0.989, 1.4647, 1.5531, 1.6552, 0.8026, 0.5685, 1.2088, 1.4039, 0.0561, 0.9972, 0.7531, 0.9152, 0.7939, 0.6706, 0.3077, 0.6605, 0.2844, 0.1642, 0.1986, 0.3486, 1.0766, 0.0793, -0.0672, 0.1227, 0.3245, 0.7012, 1.119, 1.1172, 1.115, 1.114, 1.1139, 1.1114, 1.111, 1.1102, 1.1086, 1.108, 1.1039, 1.1026, 1.0981, 1.0966, 1.0964, 1.0926, 1.0918, 1.0906, 1.0874, 1.0846, 1.0844, 1.0842, 1.082, 1.082, 1.081, 1.0797, 1.0774, 1.0772, 1.0771, 1.0771, 1.0658, 1.074, 1.0668, 1.0583, 1.0393, 1.0478, 1.0642, 1.0226, 1.0234, 1.0464, 1.0402, 0.9595, 0.9921, 1.01, 0.9943, 0.9718, 0.967, 0.9351, 1.0177, 0.8658, 0.8541, 0.9676, 0.7587, 0.9624, 0.7139, 0.7986, 0.9262, 0.8911, 0.7983, 0.8789, 0.9025, 0.5867, 0.5672, 0.0625, 0.5184, 0.4644, 0.2777, 0.6185, 0.7618, 0.4578, 0.4235, 0.6083, 0.2975, 0.0212, 0.1144, 0.4338]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 4, 5, 2, 3, 4, 5, 2, 5, 2, 5, 2, 3, 4, 5, 2, 1, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 1, 3, 5, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 5, 2, 3, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 3, 1, 4, 1, 3, 5, 1, 2, 3, 4, 5, 3, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 2, 3, 4, 3, 5, 1, 4, 5, 1, 2, 3, 4, 2, 3, 5, 3, 4, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 5, 1, 3, 5, 1, 1, 3, 4, 5, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 3, 4, 1, 3, 5, 1, 1, 3, 4, 5, 1, 1, 4, 3, 1, 3, 4, 5, 1, 2, 4, 5, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 5, 3, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 5, 5, 1, 2, 3, 4, 5, 3, 2, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 4, 5, 5, 1, 1, 4, 1, 5, 1, 2, 3, 4, 5, 3, 3, 5, 5, 2, 3, 4, 5, 1, 2, 3, 2, 2, 4, 5, 4, 1, 3, 4, 2, 3, 5, 1, 2, 3, 4, 5, 1, 4, 5, 2, 3, 3, 4, 5, 1, 3, 4, 5, 2, 5, 2, 3, 5, 5, 2, 4, 5, 2, 1, 2, 2, 3, 4, 5, 1, 2, 1, 2, 4, 1, 2, 5, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 5, 3, 1, 3, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 4, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 4, 3, 1, 1, 2, 3, 2, 1, 2, 3, 4, 5, 3, 5, 3, 5, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 3, 5, 1, 1, 1, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 5, 1, 2, 3, 4, 5, 3, 5, 5, 3, 2, 3, 5, 2, 2, 2, 3, 4, 5, 2, 3, 2, 5, 3, 5, 1, 3, 4, 5, 3, 5, 1, 3, 5, 3, 4, 5, 3, 5, 1, 4, 5, 1, 2, 3, 4, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 3, 5, 2, 3, 1, 3, 4, 5, 2, 3, 4, 5, 2, 2, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 2, 3, 1, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 5, 1, 5, 1, 2, 4, 5, 2, 4, 5, 1, 2, 3, 4, 5, 3, 4, 5, 1, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 4, 4, 5, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 1, 1, 1, 2, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 5, 5, 1, 2, 3, 5, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 4, 1, 1, 2, 3, 4, 5, 3, 5, 2, 5, 2, 3, 5, 1, 2, 3, 4, 5, 5, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 3, 4, 5, 1, 2, 3, 5, 1, 2, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 2, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 5, 2, 5, 4, 2, 1, 2, 3, 4, 5, 1, 4, 5, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 3, 5, 2, 3, 5, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 2, 1, 4, 1, 2, 3, 4, 5, 2, 3, 5, 5, 2, 3, 5, 1, 3, 2, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 4, 5, 3, 4, 5, 4, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 2, 4, 5, 1, 5, 3, 3, 5, 5, 3, 5, 5, 1, 1, 4, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 1, 3, 4, 5, 1, 2, 3, 4, 5], \"Freq\": [0.0035300678115660644, 0.26475508586745483, 0.11649223778168014, 0.03177061030409458, 0.5789311210968345, 0.17057137649290569, 0.39572559346354114, 0.10916568095545963, 0.02046856517914868, 0.30702847768723024, 0.08435768462012233, 0.5444905098207896, 0.0383444021000556, 0.015337760840022242, 0.31442409722045594, 0.1180748721906632, 0.6789305150963134, 0.20663102633366062, 0.2356500065782483, 0.15710000438549887, 0.35783889887808074, 0.02618333406424981, 0.2269222285568317, 0.09772070569160635, 0.6840449398412445, 0.09772070569160635, 0.022240419740647617, 0.05189431272817777, 0.014826946493765078, 0.9118572093665523, 0.9888477107894028, 0.9663324499110035, 0.8629531874752576, 0.14089031632249105, 0.10224383805082427, 0.8690726234320063, 0.9207429018971001, 0.08370390017246364, 0.9627593018581654, 0.033649136989523556, 0.07851465297555496, 0.2579767169196806, 0.6281172238044397, 0.11078184626075802, 0.038200636641640695, 0.1757229285515472, 0.10696178259659395, 0.5691894859604464, 0.9266346143574834, 0.9706992341824918, 0.017334059802828206, 0.6413602127046436, 0.3293471362537359, 0.8922371915832001, 0.061599494741856095, 0.46541840471624607, 0.09582143626510949, 0.061599494741856095, 0.32168625031858183, 0.6005802645556143, 0.060058026455561436, 0.060058026455561436, 0.28027079012595335, 0.9662821096215097, 0.9387057707312657, 0.7546046235196467, 0.22194253632930785, 0.5735504559683794, 0.12468488173225638, 0.1080602308346222, 0.19949581077161022, 0.7250515507195577, 0.016293293274596804, 0.057026526461088814, 0.07331981973568562, 0.11405305292217763, 0.972214632282151, 0.9958772893609852, 0.9229890574818076, 0.9456901666950642, 0.02781441666750189, 0.9815811488904276, 0.6146445157784098, 0.3782427789405599, 0.4246419806586415, 0.1711243802654227, 0.0887311601376266, 0.19013820029491413, 0.1267588001966094, 0.8025982694734296, 0.08917758549704774, 0.12326894913599924, 0.7396136948159955, 0.04108964971199975, 0.0821792994239995, 0.6923582371465448, 0.05507395068211152, 0.047206243441809875, 0.023603121720904938, 0.1730895592866362, 0.15325737592769081, 0.05108579197589694, 0.18163837146985576, 0.017028597325298978, 0.5960009063854642, 0.12310989244058755, 0.02462197848811751, 0.8371472685959953, 0.02462197848811751, 0.1024477231878634, 0.8195817855029072, 0.1024477231878634, 0.9696862926720965, 0.9523975746886502, 0.9329872396155618, 0.0363501521928141, 0.0242334347952094, 0.09926094837412479, 0.07940875869929984, 0.7543832076433484, 0.05955656902447488, 0.05361282666400257, 0.8578052266240411, 0.05361282666400257, 0.8733135563596612, 0.10274277133643073, 0.8200706445534689, 0.04932755756712595, 0.03082972347945372, 0.012331889391781488, 0.08632322574247041, 0.2145334036487951, 0.6865068916761443, 0.08581336145951804, 0.33668040182374126, 0.04927030270591336, 0.5748201982356559, 0.02463515135295668, 0.016423434235304454, 0.030713387031739117, 0.4146307249284781, 0.39927403141260853, 0.13821024164282603, 0.9864417323441783, 0.09748847789128477, 0.877396301021563, 0.03249615929709492, 0.9768965867327875, 0.45904585688099175, 0.07650764281349862, 0.3825382140674931, 0.09180917137619835, 0.030430857208409306, 0.09129257162522791, 0.5477554297513675, 0.33473942929250233, 0.898785938938845, 0.04493929694694225, 0.18700951214581432, 0.02337618901822679, 0.2571380792004947, 0.02337618901822679, 0.5096009205973441, 0.10884970356646374, 0.7619479249652462, 0.9072695879162058, 0.02419385567776549, 0.06048463919441372, 0.9673666218610982, 0.8509728038784711, 0.04478804230939321, 0.026872825385635925, 0.08061847615690779, 0.9852773090648445, 0.23927303599050817, 0.7178191079715245, 0.9406527250402839, 0.26182514485836833, 0.03967047649369217, 0.007934095298738434, 0.6902662909902437, 0.4013115497651529, 0.08026230995303058, 0.46552139772757734, 0.048157385971818345, 0.12020951045830502, 0.7212570627498301, 0.12020951045830502, 0.155107791486794, 0.7755389574339699, 0.5864648702807495, 0.032581381682263856, 0.08145345420565964, 0.10317437532716887, 0.19548829009358315, 0.07664003981905944, 0.8430404380096539, 0.02691612898714203, 0.008972042995714009, 0.06280430096999806, 0.8972042995714009, 0.06726863392345374, 0.9283071481436617, 0.1367552372432499, 0.4750445083186576, 0.15834816943955252, 0.04318586439260523, 0.17994110163585514, 0.9518105840058905, 0.01892855575963841, 0.01892855575963841, 0.05678566727891523, 0.9085706764626437, 0.9601599964211259, 0.083076429166558, 0.12461464374983698, 0.083076429166558, 0.706149647915743, 0.041538214583279, 0.940556199849965, 0.06462749451679002, 0.012925498903358005, 0.9177104221384184, 0.017084621659949797, 0.5552502039483684, 0.08542310829974899, 0.06833848663979919, 0.27335394655919676, 0.6863401787788254, 0.09804859696840364, 0.02451214924210091, 0.19609719393680727, 0.9529283216793327, 0.018684869052535934, 0.018684869052535934, 0.03789717169948475, 0.06632005047409831, 0.9000578278627628, 0.037483959330874464, 0.009370989832718616, 0.49666246113408663, 0.009370989832718616, 0.4498075119704935, 0.34372665576410344, 0.611069610247295, 0.9929673626152685, 0.97338676675182, 0.979294473338472, 0.10819789217497842, 0.757385245224849, 0.9768995888788796, 0.9476748359876069, 0.407693097725641, 0.033145780302897644, 0.1756726356053575, 0.05634782651492599, 0.32814322499868664, 0.8950452923845872, 0.016180873779477172, 0.9708524267686303, 0.9787805039056499, 0.13117676456619617, 0.04372558818873206, 0.006246512598390295, 0.8182931503891285, 0.0791039060412691, 0.8965109351343832, 0.013183984340211516, 0.9559420697842357, 0.5736186035230286, 0.019779951845621677, 0.40548901283524436, 0.9327336443370791, 0.10818539209789564, 0.10818539209789564, 0.7572977446852694, 0.015025462450893793, 0.5409166482321766, 0.43573841107592, 0.8139262515299202, 0.045218125084995564, 0.022609062542497782, 0.08478398453436668, 0.03391359381374667, 0.8319923350380903, 0.08606817259014728, 0.07172347715845606, 0.9539015449926632, 0.029809423281020726, 0.7493515779195798, 0.10705022541708284, 0.14273363388944377, 0.03196420104606777, 0.38357041255281327, 0.03196420104606777, 0.5540461514651747, 0.023699158114697933, 0.9716654827026152, 0.03412763285008224, 0.06825526570016448, 0.8873184541021383, 0.956687354410611, 0.16571014261344413, 0.7456956417604986, 0.08285507130672207, 0.9678931349753812, 0.06125344963151596, 0.9188017444727394, 0.2138333943532325, 0.23327279383989, 0.4082273892198075, 0.1360757964066025, 0.06717772980391748, 0.9068993523528859, 0.06126624730067574, 0.33696436015371656, 0.5820293493564195, 0.009442325788168124, 0.840366995146963, 0.14163488682252187, 0.9560131871408579, 0.11000638364107945, 0.6600383018464767, 0.16500957546161918, 0.027501595910269863, 0.03712305162758864, 0.22273830976553183, 0.07424610325517728, 0.6310918776690069, 0.07424610325517728, 0.27446517598036896, 0.08233955279411069, 0.13723258799018448, 0.5214838343627011, 0.8669881414158831, 0.020399720974491366, 0.010199860487245683, 0.04079944194898273, 0.0611991629234741, 0.9820025593243276, 0.8944307882266097, 0.030313322965275655, 0.030313322965275655, 0.9296085709351201, 0.06310977370092218, 0.9150917186633715, 0.7869582465362657, 0.16863390997205693, 0.3399375054559287, 0.13074519440612642, 0.05229807776245057, 0.23534134993102757, 0.23534134993102757, 0.12890884764931135, 0.7642453110637744, 0.09207774832093667, 0.039189813491233766, 0.04898726686404221, 0.10777198710089285, 0.02939236011842532, 0.7739988164518669, 0.9812936522637657, 0.9059380681022662, 0.7861484883145797, 0.09826856103932247, 0.36865103687663614, 0.11219814165810665, 0.016028305951158093, 0.21638213034063425, 0.28850950712084567, 0.03058466793181955, 0.15292333965909774, 0.7952013662273083, 0.1475940542868977, 0.7871682895301211, 0.8951328788443214, 0.9834627011564334, 0.8857721431936216, 0.09964936610928243, 0.02214430357984054, 0.9518117745527788, 0.02009352452157923, 0.11051438486868577, 0.4470809206051379, 0.02511690565197404, 0.4018704904315846, 0.803057155876331, 0.08922857287514789, 0.046430146564146506, 0.9518180045650034, 0.7500062788906924, 0.16304484323710705, 0.06521793729484282, 0.6763128201432113, 0.06763128201432113, 0.05260210823336088, 0.007514586890480126, 0.19537925915248325, 0.9817144087387883, 0.9545468295141699, 0.5287407384626454, 0.17298308110197655, 0.07506812953482002, 0.08159579297263045, 0.1403447639129244, 0.9476733630631663, 0.8913127147679232, 0.006803913853190253, 0.006803913853190253, 0.006803913853190253, 0.08164696623828303, 0.9712473955570696, 0.007185450671562436, 0.03233452802203096, 0.19041444279640457, 0.007185450671562436, 0.7652504965213994, 0.2564039487054793, 0.11563315333776515, 0.20612866464558136, 0.19607360783360178, 0.22623877826954053, 0.9212301066540343, 0.09326702996165862, 0.8860367846357567, 0.04663351498082931, 0.9655539881819858, 0.9723264791301528, 0.9792950027211752, 0.09056374202200326, 0.9056374202200326, 0.2622355780242055, 0.28523869890352177, 0.12421685274830788, 0.12421685274830788, 0.20702808791384647, 0.611997545918169, 0.09761924045320489, 0.08635548193937355, 0.015018344685108443, 0.18772930856385553, 0.48068899112485325, 0.04721052591404808, 0.10300478381246855, 0.3648086093358261, 0.9802975320496827, 0.024752105214758742, 0.19801684171806994, 0.668306840798486, 0.012376052607379371, 0.09900842085903497, 0.034062427911468934, 0.9196855536096612, 0.9929697510512149, 0.8950149873400487, 0.5733102134550786, 0.030713047149379207, 0.3890319305588033, 0.9625495478203454, 0.927185547483257, 0.0895039880287513, 0.1790079760575026, 0.5668585908487582, 0.1790079760575026, 0.9337997453692513, 0.05492939678642655, 0.9444953033246104, 0.04843565658074925, 0.8174573625058424, 0.125762671154745, 0.5757123112980115, 0.13057392627377581, 0.01780553540096943, 0.2730182094815312, 0.05895717411693781, 0.9433147858710049, 0.061218531754095556, 0.020406177251365187, 0.9182779763114334, 0.11404868199734505, 0.015206490932979341, 0.8667699831798225, 0.5904070886468018, 0.4076620373989822, 0.8728921591835725, 0.022098535675533482, 0.09944341053990068, 0.7034310550908787, 0.015748456457258475, 0.05774434034328108, 0.07349279680053956, 0.14698559360107913, 0.8717472970773923, 0.9797057436224231, 0.11898687990059409, 0.3779583243901224, 0.11198765167114737, 0.1959783904245079, 0.1959783904245079, 0.06072233773810537, 0.010120389623017562, 0.38457480567466734, 0.5465010396429484, 0.020917345962625816, 0.04183469192525163, 0.690272416766652, 0.08366938385050326, 0.16733876770100653, 0.09986775503505504, 0.03328925167835168, 0.03328925167835168, 0.5659172785319786, 0.26631401342681343, 0.6527521719650521, 0.049733498816384926, 0.05595018616843304, 0.12433374704096231, 0.1181170596889142, 0.9883688836775274, 0.11270666474155863, 0.06762399884493518, 0.04508266589662345, 0.47336799191454626, 0.2930373283280524, 0.4630462878119839, 0.06257382267729512, 0.13140502762231976, 0.16894932122869682, 0.16894932122869682, 0.9769022223575647, 0.6759710775394375, 0.042248192346214845, 0.03802337311159336, 0.10139566163091564, 0.14364385397713048, 0.9338180774548875, 0.011672725968186094, 0.046690903872744376, 0.8713902139065295, 0.03788653103941433, 0.07577306207882865, 0.5820353009541028, 0.0107123061525295, 0.064273836915177, 0.10355229280778516, 0.23924150407315883, 0.02381910939125571, 0.5240204066076256, 0.10718599226065069, 0.2977388673906964, 0.04763821878251142, 0.9385818989191993, 0.8083651916711045, 0.11887723406928008, 0.04755089362771203, 0.9482486230479519, 0.023706215576198796, 0.09735987489551386, 0.2677396559626631, 0.4624594057536908, 0.17037978106714924, 0.8719479533505532, 0.01937662118556785, 0.0775064847422714, 0.01937662118556785, 0.9625562608186616, 0.9684657486332257, 0.6446124177448461, 0.019533709628631702, 0.33207306368673895, 0.11269566690127968, 0.049304354269309854, 0.11269566690127968, 0.01408695836265996, 0.7113913973143279, 0.32940556835774526, 0.11503051593445074, 0.20391773279288994, 0.12025917574965304, 0.22483237205369916, 0.8158575295357331, 0.010072315179453496, 0.02014463035890699, 0.15108472769180242, 0.89607081272287, 0.09956342363587445, 0.860357003268611, 0.13475471135532463, 0.05093198551777378, 0.12732996379443445, 0.10186397103554756, 0.5602518406955116, 0.17826194931220823, 0.9884026747614931, 0.259329160419078, 0.0648322901047695, 0.2515492856065057, 0.425299823087288, 0.9880207062486417, 0.009782383230184571, 0.1692334079173535, 0.05641113597245117, 0.676933631669414, 0.11282227194490234, 0.24934747813577346, 0.7480424344073204, 0.9476703522139852, 0.13450163204286356, 0.3200211245157788, 0.09275974623645762, 0.023189936559114405, 0.43133281999952794, 0.13788775258184557, 0.012535250234713234, 0.8398617657257867, 0.9570573600545271, 0.7656774696014658, 0.059406010572527514, 0.026402671365567783, 0.01980200352417584, 0.13201335682783893, 0.32533128461674143, 0.455463798463438, 0.20821202215471452, 0.06558221166396966, 0.4955100436833263, 0.09472986129240062, 0.0728691240710774, 0.26961575906298635, 0.9382651880183774, 0.12091809387584274, 0.8464266571308992, 0.6810942864492233, 0.019915037615474366, 0.09559218055427696, 0.11550721816975133, 0.08762616550808722, 0.9814848879250353, 0.21527250531911746, 0.7175750177303916, 0.8423806137181725, 0.12034008767402464, 0.9545511845907312, 0.07207881288516359, 0.018019703221290897, 0.12613792254903627, 0.783857090126154, 0.2959873378369725, 0.09107302702676077, 0.15558308783738298, 0.09486773648620914, 0.3604973986475947, 0.9037012035214057, 0.9899328419639639, 0.464862834565053, 0.16904103075092838, 0.10565064421933024, 0.10036811200836372, 0.15319343411802885, 0.03735765517834298, 0.6973428966624023, 0.024905103452228655, 0.12452551726114329, 0.11207296553502895, 0.23912506933231414, 0.7173752079969424, 0.9864970404541935, 0.9885028133499312, 0.9530030163041907, 0.050158053489694245, 0.020936205589258607, 0.07327671956240513, 0.08374482235703443, 0.010468102794629303, 0.8165120179810857, 0.14704474655004512, 0.8287976623729817, 0.02673540846364457, 0.08002003797154442, 0.34408616327764097, 0.12803206075447107, 0.1760440835373977, 0.28007013290040544, 0.9555712107958584, 0.03686196459693383, 0.02345761383441244, 0.08377719226575872, 0.016755438453151743, 0.8411230103482175, 0.956654577506392, 0.9476768884435908, 0.04091183733612407, 0.7977808280544194, 0.10227959334031018, 0.08182367467224815, 0.727490671842363, 0.0352011615407595, 0.08213604359510551, 0.15253836667662451, 0.7900344545300891, 0.07900344545300891, 0.015800689090601783, 0.11060482363421248, 0.004297499021786567, 0.2879324344597, 0.14181746771895673, 0.025784994130719406, 0.5414848767451075, 0.010245504195000086, 0.03073651258500026, 0.08196403356000069, 0.8708678565750074, 0.4871595860114899, 0.008699278321633747, 0.06089494825143624, 0.4349639160816874, 0.00987092014823588, 0.10858012163059469, 0.15299926229765615, 0.01974184029647176, 0.7156417107471014, 0.8148605897885374, 0.15278636058535075, 0.13889244855456181, 0.13889244855456181, 0.694462242772809, 0.9834604687357855, 0.01371633216671191, 0.6858166083355955, 0.06858166083355954, 0.05486532866684764, 0.19202865033396674, 0.8004386050528536, 0.1778752455673008, 0.9034899719665304, 0.0821354519969573, 0.05340913383272656, 0.8011370074908984, 0.10681826766545312, 0.01103060538749191, 0.04412242154996764, 0.07721423771244337, 0.02206121077498382, 0.8493566148368771, 0.9693460903060005, 0.9712414836013237, 0.6446935711872734, 0.019244584214545477, 0.05773375264363643, 0.2790464711109094, 0.1843554708234948, 0.0460888677058737, 0.5837923242744001, 0.0460888677058737, 0.12290364721566319, 0.8148605898229665, 0.15278636059180623, 0.5082149624279992, 0.08470249373799989, 0.13175943470355536, 0.09411388193111098, 0.17881637566911085, 0.9120498096199827, 0.019405315098297505, 0.019405315098297505, 0.04851328774574376, 0.5994796306526563, 0.053928083929004646, 0.003762424460163115, 0.34238062587484347, 0.03359292046591855, 0.5626814178041357, 0.016796460232959276, 0.38631858535806335, 0.9490371206980383, 0.026362142241612176, 0.021626441388038372, 0.08650576555215349, 0.021626441388038372, 0.06487932416411513, 0.7893651106634006, 0.9285065328290666, 0.05803165830181666, 0.008069986700379448, 0.06455989360303559, 0.06455989360303559, 0.016139973400758897, 0.8473486035398421, 0.019227850331046768, 0.980620366883385, 0.04830327891580775, 0.3477836081938158, 0.11109754150635782, 0.49269344494123907, 0.34052497699452855, 0.14935306008531954, 0.12545657047166842, 0.17324954969897066, 0.20909428411944736, 0.8823734981330725, 0.0534771817050347, 0.0534771817050347, 0.030811534595972738, 0.046217301893959103, 0.07702883648993185, 0.8473172013892503, 0.9575785221238022, 0.033599246390308854, 0.9059156959133563, 0.9731301162849856, 0.16032743708111802, 0.07125663870271913, 0.0890707983783989, 0.5522389499460733, 0.12469911772975847, 0.02836437511002028, 0.7658381279705475, 0.19855062577014193, 0.1496501843177357, 0.7482509215886785, 0.07482509215886785, 0.9105291983365698, 0.05690807489603561, 0.03793871659735707, 0.2401678640807667, 0.34103836699468876, 0.09126378835069135, 0.23536450679915139, 0.09606714563230669, 0.9348732157339926, 0.054195548738202474, 0.013548887184550619, 0.01268106435841708, 0.5579668317703516, 0.43115618818618073, 0.9202119835548856, 0.053936719368870345, 0.7551140711641848, 0.08989453228145057, 0.08989453228145057, 0.010191761284510145, 0.01834517031211826, 0.19160511214879072, 0.09376420381749333, 0.6869247105759838, 0.0059628885520766495, 0.047703108416613196, 0.25938565201533426, 0.03279588703642157, 0.6559177407284315, 0.7569226784256428, 0.08410251982507141, 0.016820503965014284, 0.13456403172011427, 0.9277513794007949, 0.04882901996846289, 0.1295956740451861, 0.19439351106777916, 0.016199459255648262, 0.35638810362426177, 0.29159026660166876, 0.9386919504806468, 0.9545467686505329, 0.9049561412413171, 0.027714381696372435, 0.4572872979901452, 0.027714381696372435, 0.020785786272279328, 0.47114448883833143, 0.8855675136802097, 0.02604610334353558, 0.05209220668707116, 0.9565238623352617, 0.02265762160118234, 0.4814744590251247, 0.49846767522601143, 0.11093452414775565, 0.8504980184661266, 0.9048469107535121, 0.03480180425975046, 0.03480180425975046, 0.8736126473746071, 0.042964556428259366, 0.014321518809419788, 0.042964556428259366, 0.028643037618839576, 0.7144882567033641, 0.04154001492461419, 0.04154001492461419, 0.19939207163814812, 0.06507787749077788, 0.9110902848708904, 0.731164508068071, 0.2580580616710839, 0.829918262139471, 0.02677155684320874, 0.13385778421604372, 0.9044333622622632, 0.04439099513062441, 0.014796998376874803, 0.5178949431906181, 0.014796998376874803, 0.4291129529293693, 0.03614761370377211, 0.19388265532023222, 0.013144586801371677, 0.7558137410788714, 0.11393574227877389, 0.4911023374085081, 0.08250519268462937, 0.11786456097804196, 0.1925121162641352, 0.95247041692488, 0.10736882588203818, 0.2415798582345859, 0.10736882588203818, 0.5636863358807004, 0.04811671467000994, 0.817984149390169, 0.12029178667502484, 0.9793277275680445, 0.9565142233561221, 0.9418788094166352, 0.8578902420036119, 0.07149085350030099, 0.9689792826018099, 0.10600069571261979, 0.8833391309384983, 0.9565217434192732, 0.9768996351649006, 0.9654159928758566, 0.020987304192953405, 0.9587897811508105, 0.034242492183957515, 0.34418430498810576, 0.5039841608754406, 0.006146148303359032, 0.06760763133694934, 0.07989992794366742, 0.5154095194322291, 0.15718162649351666, 0.12062775986711745, 0.05483079993959884, 0.15352623983087674, 0.8975004015919432, 0.03648375616227412, 0.06567076109209341, 0.07662135773703357, 0.04788834858564598, 0.5171941647249766, 0.02873300915138759, 0.3256407703823927, 0.9552162690541443, 0.0360458969454394, 0.2559297387123655, 0.2869515252229553, 0.06592129633500325, 0.1551089325529488, 0.24041884545707065, 0.23916336530113, 0.04312781997233492, 0.12938345991700476, 0.07449350722494212, 0.513613128761443, 0.9769121407944377, 0.9545491231816898, 0.3045072589404513, 0.033834139882272365, 0.07443510774099919, 0.5887140339515391, 0.7037137966352313, 0.014815027297583817, 0.07407513648791908, 0.10370519108308672, 0.10370519108308672], \"Term\": [\"000\", \"000\", \"000\", \"000\", \"000\", \"10\", \"10\", \"10\", \"10\", \"10\", \"1960\", \"1960\", \"1960\", \"1960\", \"1960\", \"1962\", \"1962\", \"1962\", \"30\", \"30\", \"30\", \"30\", \"30\", \"aboard\", \"aboard\", \"aboard\", \"administration\", \"administration\", \"administration\", \"administration\", \"af\", \"africa\", \"aircraft\", \"aircraft\", \"alaska\", \"alaska\", \"alexander\", \"alexander\", \"allocation\", \"america\", \"america\", \"america\", \"america\", \"american\", \"american\", \"american\", \"american\", \"american\", \"animals\", \"anne\", \"anti\", \"anti\", \"anti\", \"apparatus\", \"area\", \"area\", \"area\", \"area\", \"area\", \"areas\", \"areas\", \"areas\", \"areas\", \"assessment\", \"associations\", \"aug\", \"aug\", \"available\", \"available\", \"available\", \"available\", \"away\", \"away\", \"away\", \"away\", \"away\", \"baby\", \"ball\", \"bargaining\", \"bed\", \"bed\", \"bedroom\", \"berlin\", \"berlin\", \"better\", \"better\", \"better\", \"better\", \"better\", \"beverly\", \"beverly\", \"bible\", \"bible\", \"bible\", \"bible\", \"big\", \"big\", \"big\", \"big\", \"big\", \"board\", \"board\", \"board\", \"board\", \"board\", \"boat\", \"boat\", \"boat\", \"boat\", \"bomb\", \"bomb\", \"bomb\", \"bombs\", \"bond\", \"boy\", \"boy\", \"boy\", \"bridge\", \"bridge\", \"bridge\", \"bridge\", \"bridges\", \"bridges\", \"bridges\", \"bus\", \"bus\", \"came\", \"came\", \"came\", \"came\", \"came\", \"captain\", \"captain\", \"captain\", \"car\", \"car\", \"car\", \"car\", \"car\", \"cars\", \"cars\", \"cars\", \"cars\", \"castro\", \"catholic\", \"catholic\", \"catholic\", \"charlie\", \"child\", \"child\", \"child\", \"child\", \"china\", \"china\", \"china\", \"china\", \"churches\", \"churches\", \"city\", \"city\", \"city\", \"city\", \"city\", \"clarity\", \"clarity\", \"clay\", \"clay\", \"clay\", \"clothes\", \"club\", \"club\", \"club\", \"club\", \"coach\", \"collar\", \"collar\", \"collections\", \"college\", \"college\", \"college\", \"college\", \"color\", \"color\", \"color\", \"color\", \"column\", \"column\", \"column\", \"columns\", \"columns\", \"come\", \"come\", \"come\", \"come\", \"come\", \"commissioners\", \"commissioners\", \"committee\", \"committee\", \"committee\", \"committee\", \"communist\", \"communist\", \"company\", \"company\", \"company\", \"company\", \"company\", \"components\", \"conference\", \"conference\", \"conference\", \"conference\", \"congressional\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\", \"corporate\", \"corps\", \"corps\", \"corps\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"costs\", \"costs\", \"costs\", \"costs\", \"couldn\", \"couldn\", \"couldn\", \"county\", \"county\", \"county\", \"court\", \"court\", \"court\", \"court\", \"court\", \"cousin\", \"cousin\", \"cuba\", \"cuban\", \"cup\", \"dancer\", \"dancer\", \"dave\", \"davis\", \"day\", \"day\", \"day\", \"day\", \"day\", \"deadline\", \"democratic\", \"democratic\", \"democrats\", \"department\", \"department\", \"department\", \"department\", \"design\", \"design\", \"design\", \"designers\", \"development\", \"development\", \"development\", \"discipline\", \"discovery\", \"discovery\", \"discovery\", \"district\", \"district\", \"district\", \"don\", \"don\", \"don\", \"don\", \"don\", \"door\", \"door\", \"door\", \"drill\", \"drill\", \"driver\", \"driver\", \"driver\", \"east\", \"east\", \"east\", \"east\", \"economic\", \"economic\", \"education\", \"education\", \"education\", \"el\", \"electricity\", \"electricity\", \"electricity\", \"electronic\", \"electronics\", \"electronics\", \"employees\", \"employees\", \"employees\", \"employees\", \"engine\", \"engine\", \"engineer\", \"engineer\", \"engineer\", \"equipment\", \"equipment\", \"equipment\", \"ethics\", \"europe\", \"europe\", \"europe\", \"europe\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"exercise\", \"eye\", \"eye\", \"eye\", \"eye\", \"eyes\", \"eyes\", \"eyes\", \"eyes\", \"eyes\", \"faculty\", \"fashioned\", \"feed\", \"feed\", \"feed\", \"fig\", \"fig\", \"filing\", \"filing\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fiscal\", \"fiscal\", \"fiscal\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"foreign\", \"forests\", \"fortunate\", \"fortune\", \"fortune\", \"found\", \"found\", \"found\", \"found\", \"found\", \"foundation\", \"foundation\", \"foundation\", \"frames\", \"frames\", \"frontier\", \"gallery\", \"game\", \"game\", \"game\", \"gear\", \"general\", \"general\", \"general\", \"general\", \"general\", \"generations\", \"generations\", \"georgia\", \"georgia\", \"german\", \"german\", \"german\", \"going\", \"going\", \"going\", \"going\", \"going\", \"golden\", \"golf\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gop\", \"got\", \"got\", \"got\", \"got\", \"got\", \"gov\", \"government\", \"government\", \"government\", \"government\", \"government\", \"great\", \"great\", \"great\", \"great\", \"great\", \"greece\", \"gross\", \"gross\", \"gross\", \"hadn\", \"hair\", \"ham\", \"heating\", \"heating\", \"high\", \"high\", \"high\", \"high\", \"high\", \"home\", \"home\", \"home\", \"home\", \"home\", \"house\", \"house\", \"house\", \"house\", \"hughes\", \"income\", \"income\", \"income\", \"income\", \"income\", \"independence\", \"independence\", \"india\", \"indiana\", \"industry\", \"industry\", \"industry\", \"insert\", \"installation\", \"insurance\", \"insurance\", \"insurance\", \"insurance\", \"interference\", \"interference\", \"interior\", \"interior\", \"islands\", \"islands\", \"john\", \"john\", \"john\", \"john\", \"judge\", \"judge\", \"jury\", \"jury\", \"jury\", \"kennedy\", \"kennedy\", \"kennedy\", \"khrushchev\", \"khrushchev\", \"knew\", \"knew\", \"knew\", \"know\", \"know\", \"know\", \"know\", \"know\", \"ladder\", \"laos\", \"large\", \"large\", \"large\", \"large\", \"large\", \"law\", \"law\", \"law\", \"law\", \"laws\", \"laws\", \"laws\", \"laws\", \"laws\", \"learned\", \"learned\", \"learned\", \"learned\", \"learned\", \"left\", \"left\", \"left\", \"left\", \"left\", \"legislature\", \"letters\", \"letters\", \"letters\", \"letters\", \"letters\", \"life\", \"life\", \"life\", \"life\", \"life\", \"listening\", \"little\", \"little\", \"little\", \"little\", \"little\", \"looked\", \"looked\", \"looked\", \"machine\", \"machine\", \"machine\", \"man\", \"man\", \"man\", \"man\", \"man\", \"management\", \"management\", \"management\", \"management\", \"management\", \"manufacturer\", \"manufacturers\", \"manufacturers\", \"manufacturers\", \"marketing\", \"marketing\", \"martin\", \"martin\", \"martin\", \"martin\", \"materials\", \"materials\", \"materials\", \"materials\", \"measurement\", \"measurements\", \"medical\", \"medical\", \"medical\", \"members\", \"members\", \"members\", \"members\", \"members\", \"men\", \"men\", \"men\", \"men\", \"men\", \"miss\", \"miss\", \"miss\", \"miss\", \"missile\", \"missile\", \"mother\", \"mother\", \"motor\", \"motor\", \"motor\", \"motor\", \"motor\", \"motors\", \"mr\", \"mr\", \"mr\", \"mr\", \"mrs\", \"mrs\", \"muscle\", \"muscle\", \"muscle\", \"muscle\", \"muscles\", \"muscles\", \"nam\", \"national\", \"national\", \"national\", \"national\", \"national\", \"nations\", \"nations\", \"nations\", \"nice\", \"night\", \"night\", \"night\", \"night\", \"night\", \"nuclear\", \"nuclear\", \"nuclear\", \"number\", \"number\", \"number\", \"number\", \"number\", \"objectives\", \"odd\", \"odd\", \"old\", \"old\", \"old\", \"old\", \"old\", \"orchestra\", \"paint\", \"paint\", \"painted\", \"painted\", \"pale\", \"peace\", \"peace\", \"peace\", \"peace\", \"people\", \"people\", \"people\", \"people\", \"people\", \"phases\", \"pink\", \"place\", \"place\", \"place\", \"place\", \"place\", \"plant\", \"plant\", \"plant\", \"plant\", \"plant\", \"plastic\", \"plastic\", \"player\", \"players\", \"playing\", \"playing\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"pool\", \"pool\", \"pool\", \"possible\", \"possible\", \"possible\", \"possible\", \"possible\", \"precision\", \"president\", \"president\", \"president\", \"president\", \"president\", \"presidential\", \"priority\", \"product\", \"product\", \"product\", \"product\", \"production\", \"production\", \"production\", \"production\", \"products\", \"products\", \"products\", \"products\", \"program\", \"program\", \"program\", \"program\", \"program\", \"property\", \"property\", \"property\", \"property\", \"provide\", \"provide\", \"provide\", \"provide\", \"public\", \"public\", \"public\", \"public\", \"public\", \"puerto\", \"puerto\", \"push\", \"push\", \"push\", \"quietly\", \"range\", \"range\", \"range\", \"range\", \"range\", \"rayburn\", \"rayburn\", \"recreation\", \"recreation\", \"rehabilitation\", \"rehabilitation\", \"rehabilitation\", \"report\", \"report\", \"report\", \"report\", \"report\", \"republican\", \"republicans\", \"research\", \"research\", \"research\", \"research\", \"return\", \"return\", \"return\", \"return\", \"return\", \"rico\", \"rico\", \"right\", \"right\", \"right\", \"right\", \"right\", \"room\", \"room\", \"room\", \"room\", \"said\", \"said\", \"said\", \"said\", \"sales\", \"sales\", \"sales\", \"sales\", \"sat\", \"sat\", \"schools\", \"schools\", \"schools\", \"schools\", \"schools\", \"screw\", \"screw\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"secretary\", \"senate\", \"senate\", \"service\", \"service\", \"service\", \"service\", \"set\", \"set\", \"set\", \"set\", \"set\", \"sets\", \"sets\", \"sets\", \"shall\", \"shall\", \"shall\", \"shall\", \"shelter\", \"shelter\", \"shifted\", \"shipments\", \"sign\", \"sign\", \"sign\", \"sign\", \"sign\", \"signs\", \"signs\", \"signs\", \"sir\", \"sir\", \"sir\", \"site\", \"site\", \"site\", \"small\", \"small\", \"small\", \"small\", \"small\", \"son\", \"son\", \"son\", \"soviet\", \"soviet\", \"soviet\", \"soviets\", \"standard\", \"standard\", \"standard\", \"standard\", \"state\", \"state\", \"state\", \"state\", \"state\", \"states\", \"states\", \"states\", \"states\", \"states\", \"stations\", \"stations\", \"stations\", \"stations\", \"stockholders\", \"stockholders\", \"strength\", \"strength\", \"strength\", \"strength\", \"strength\", \"structural\", \"susan\", \"swallowed\", \"system\", \"system\", \"system\", \"system\", \"system\", \"systems\", \"systems\", \"systems\", \"tangible\", \"tax\", \"tax\", \"tax\", \"tests\", \"tests\", \"textile\", \"textile\", \"textile\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"took\", \"took\", \"took\", \"took\", \"tool\", \"tool\", \"tractor\", \"tractor\", \"trust\", \"trust\", \"trust\", \"ugliness\", \"union\", \"union\", \"union\", \"union\", \"union\", \"united\", \"united\", \"united\", \"united\", \"use\", \"use\", \"use\", \"use\", \"use\", \"va\", \"vacation\", \"vacation\", \"vacation\", \"vacation\", \"vehicles\", \"vehicles\", \"vehicles\", \"vernon\", \"viet\", \"virgin\", \"vocational\", \"vocational\", \"volunteers\", \"vote\", \"vote\", \"voters\", \"waited\", \"walked\", \"walked\", \"wasn\", \"wasn\", \"water\", \"water\", \"water\", \"water\", \"water\", \"way\", \"way\", \"way\", \"way\", \"way\", \"went\", \"went\", \"went\", \"west\", \"west\", \"west\", \"west\", \"west\", \"woman\", \"woman\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"world\", \"yard\", \"yards\", \"york\", \"york\", \"york\", \"york\", \"young\", \"young\", \"young\", \"young\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el3279221728612657601873148056\", ldavis_el3279221728612657601873148056_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el3279221728612657601873148056\", ldavis_el3279221728612657601873148056_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el3279221728612657601873148056\", ldavis_el3279221728612657601873148056_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3d14c87",
   "metadata": {},
   "source": [
    "Q: What conclusions do you draw from the visualization above? Please address the principal component scatterplot and the salient terms graph.\n",
    "\n",
    "A: According to the principal component scatterplot, the topics 1, 2, and 4 appear to quite distinct based on the LDA model. However, Topics 3 and 5 are actually overlapping, suggesting a similarity and the possibility that the LDA model did not properly separate the themes, or that the two topics had similar themes without much disparity. However, when comparing the two topics in the salient terms graph, there does not appear to be much crossover in the actual text itself. It is worth noting that topic 5 is covers a large amount of the frequency of each corresponding term in the overall term frequency. This would suggest that topic 5 is either a large topic being discussed or a common topic within multiple thematic elements that can cross over into other topics within the corpus. Overall, the salient terms graph appears to have terms that are politically driven and from a professional corpus, suggesting that the LDA model did pull the significant themes and terms correctly.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
